---
title: "Investigating How Phenotype Differences Handles Information Asymmetry With Multiple Siblings"
author: "Klint Kanopka"
date: "10/19/2020"
output: pdf_document
---

Load `MASS` before you load `dplyr` or `tidyverse`, or else things get weird with the `select()` function.

```{r setup, results='hide', message=FALSE, warning=FALSE}
library(tidyverse)
library(parallel)
```

# Simulation Function

## Simulating genetic data

We first focus on a single trait. Note that in the simulation function, $N$ specifies the number of *families*. For the $j$th family, we draw parental phenotypes $g_{jm}, g_{jp} \in \{0,1,2\}$ such that

$$g_{jm} \sim \text{Binomial}(2, p_{allele})$$
Where $p_{allele}$ is the prevalence of the allele in the parent's generation. Note that $g_{jp}$ is drawn the same way. This can be specified in the simulation function. Next, for the genotype of each of the three siblings birthed of these parents $(g_{ij}\in\{0,1,2\}\text{, where } i\in\{0,1,2\})$, one allele is drawn from each parent at random such that

$$g_{ij} \sim \text{Bernoulli}\bigg(\frac{g_{jm}}{2}\bigg) + \text{Bernoulli}\bigg(\frac{g_{jp}}{2}\bigg)$$

## Simulating phenotypes

The `sim.data()` function allows for specifying the relative magnitudes of the direct genetic effect, $\beta$, a pooled family-level genetic and environmental effect, $\gamma_1$, and the individual error term, $\gamma_2$. We specify these three coefficients instead of specifying standard deviations for the $\varepsilon_j$ and $\varepsilon_{ij}$ terms for simplicity.

This function simulates a dichotomous phenotype, $Y_{ij}$, for three siblings, $i \in \{0,1,2\}$. Note that sibling $i=0$ is taken to be the genotyped sibling, though genotypes are generated for each sibling under the hood. Dichotomization is done by doing Bernoulli draws for each sibling where

$$Y_{ij} \sim \text{Bernoulli}(p_{ij})$$
where

$$p_{ij} = \sigma \big(\alpha + \beta g_{ij} + \gamma_1 \varepsilon_j + \gamma_2 \varepsilon_{ij}\big) $$
Where $i$ indexes siblings, $j$ indexes families and $\sigma(\cdot)$ is the standard logistic sigmoid. Note that in the simulations that follow, we will not estimate $\beta$ directly - but instead fit a linear probability model to the simulated data. 

Adjust the beta/gamma_1/gamma_2 coefs to get R^2 ~ 0.001

```{r simulation_function}
sim.data <- function(N=1e5, rho=0.5, rho_g=0.3, p_allele=0.3, 
                     alpha=-1, beta=0.04, gamma_1=sqrt(0.35),   gamma_2=sqrt(0.649),
                     continuous=FALSE){

  sim.genes <- function(N=N, rho=rho, rho_g=rho_g, p_allele=p_allele){
    g_m <- rbinom(n=N, size=2, prob=p_allele)
    g_p <- rbinom(n=N, size=2, prob=p_allele)

    out <- data.frame(g_m = g_m, 
                      g_p = g_p,
                      g0 = rbinom(N, 1, g_m/2) + rbinom(N, 1, g_m/2),
                      g1 = rbinom(N, 1, g_m/2) + rbinom(N, 1, g_m/2),
                      g2 = rbinom(N, 1, g_m/2) + rbinom(N, 1, g_m/2),
                      eps_fam = rnorm(N))
    return(out)
  }

  sigmoid <- function(z){
    out <- 1 / (1 + exp(-z))
  }

  a <- rep(alpha, N)
  b <- rep(beta, N)

  d <- sim.genes(N=N, rho=rho, rho_g=rho_g, p_allele=p_allele)
  
  if (continuous){
    d$Y0 <- a + b*d$g0 + gamma_1*d$eps_fam + gamma_2*rnorm(N)
    d$Y1 <- a + b*d$g1 + gamma_1*d$eps_fam + gamma_2*rnorm(N)
    d$Y2 <- a + b*d$g2 + gamma_1*d$eps_fam + gamma_2*rnorm(N)
  } else {
    d$p0 <- sigmoid(a + b*d$g0 + gamma_1*d$eps_fam + gamma_2*rnorm(N))
    d$p1 <- sigmoid(a + b*d$g1 + gamma_1*d$eps_fam + gamma_2*rnorm(N))
    d$p2 <- sigmoid(a + b*d$g2 + gamma_1*d$eps_fam + gamma_2*rnorm(N))
  
    d$Y0 <- rbinom(N, 1, d$p0)
    d$Y1 <- rbinom(N, 1, d$p1)
    d$Y2 <- rbinom(N, 1, d$p2)
  }
  return(d)
}
```


# A Fast Comparison of Vanilla OLS, Fixed-Effects, and Phenotype Differences

If we want to estimate the effect of a genotype, $g$ on $Y$, we can use data from genotyped siblings and run a regression. This has the downside of being biased due to the presence of omitted variables (specifically at the family level) that are correlated with both our predictors and the outcome. 

```{r ols}
set.seed(8675309)
d <- sim.data(continuous=TRUE)
m_ols <- lm(Y0 ~ g0, data = d)
summary(m_ols)
```

A fixed effects regression gets around this. Here I use genotype data from all three simulated siblings to give our best estimate of the effect we are looking to recover:

```{r fe}
# apply within transformation
fe_d <- data.frame(
  Y = c(d$Y0, d$Y1, d$Y2),
  g = c(d$g0, d$g1, d$g2),
  family = rep(1:nrow(d), 3)) %>% 
  group_by(family) %>% 
  mutate(Y_bar = mean(Y),
         g_bar = mean(g)) %>% 
  ungroup() %>% 
  transmute(Y = Y - Y_bar,
            g = g - g_bar)

m_fe <- lm(Y ~ g, data = fe_d)
summary(m_fe)
```

Unfortunately, it is not always the case that we have sets of siblings that are all genotyped. Here is where phenotype differences methods are helpful, as they are (theoretically) unbiased when we observe two phenotypes within the same family and only one genotyped sibling. Note that here, PD does not appear to recover the correct estimates.

```{r}
d <- d %>% 
  mutate(g_pd = 0.5 * g0,
         delta_g1 = g0 - g1,
         delta_g2 = g0 - g2,
         delta_Y1 = Y0 - Y1,
         delta_Y2 = Y0 - Y2,
         delta_max = Y0 - max(Y1, Y2),
         keep = 1 - max(Y1, Y2))

#FD Models
m1 <- lm(delta_Y1 ~ delta_g1, data = d)
m2 <- lm(delta_Y2 ~ delta_g2, data = d)
summary(m1)
summary(m2)

#PD Models
m1 <- lm(delta_Y1 ~ g_pd, data = d)
m2 <- lm(delta_Y2 ~ g_pd, data = d)
summary(m1)
summary(m2)
```


# A Motivating Example

Next imagine the case where there are three phenotyped siblings and we ask the genotyped sibling, "Do either of your siblings have phenotype $Y$?" Some data in the UKB is collected this way. Additionally, it is easy to imagine a selection design that does this implicitly - providing us with a nonrandom phenotyped sibling. As one would expect, this case provides an estimate of the direct genetic effect that is biased:

```{r}
m3 <- lm(delta_max ~ g_pd, data = d)
summary(m3)
max_est <- coef(m3)[2]
```
